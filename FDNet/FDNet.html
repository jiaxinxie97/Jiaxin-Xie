<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-173182823-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        
        gtag('config', 'UA-173182823-1');
    </script>

    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>Video Depth Estimation by Fusing Flow-to-Depth Proposals (FDNet)</title>
    <meta name="author" content="Jiaxin Xie">
    <meta name="description" content="Project page of Video Depth Estimation by Fusing Flow-to-Depth Proposals, IROS 2020">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="eccv_logo.png">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>

  </head>

  <body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                Video Depth Estimation by<br /> 
                Fusing Flow-to-Depth Proposals <br />
                <small>
                    IROS 2020
                </small>
            </h1>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a>
                            Jiaxin Xie
                        </a>
                        <br /> &nbsp
                    </li>

                    <li>
                         <a href="https://chenyanglei.github.io/">
                            Chenyang Lei
                        </a>
                        <br /> &nbsp
                        
                    </li>
                    <li>
                         <a>
                            Zhuwen Li
                        </a>
                        <br /> &nbsp
                        
                    </li>
                    <li>
                        <a href="http://www.cs.columbia.edu/~lierranli/">
                            Li Erran Li
                        </a>
                        <br /> &nbsp
                        
                    </li>
                    <li>
                        <a href="https://cqf.io/">
                           Qifeng Chen
                        </a>
                        <br /> &nbsp
                    </li>
                </ul>
            </div>
        </div>

        <!-- <div class="row">
            <div class="col-md-12 text-center">
                Some more comments
            </div>
        </div> -->

        <!-- ##### Elements #####-->
        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/pdf/1912.12874.pdf">
                            <img src="../images/FDNet_paper.PNG" height="120px"><br>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
<!--                             <a href="https://youtu.be/eN4BBVUJ2NQ"> -->
                            <a href="https://github.com/jiaxinxie97/Video-depth-estimation.git">
                            <img src="../images/github_icon.png" height="120px"><br>
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://www.youtube.com/watch?v=ajwKvvoxeHw">
                            <img src="../images/youtube_icon.png" height="120px"><br>
                                <h4><strong>Talk</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>


        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Example Results
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="lighthouse_results.mp4" type="video/mp4" />
                </video>
            </div>
        </div> -->

        <!-- ##### Abstract #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Depth from a monocular video can enable billions of devices and robots with a single camera to see the world in 3D.
                    In this paper, we present an approach with a differentiable flow to-depth layer for video depth estimation. The model consists
                    of a flow-to-depth layer, a camera pose refinement module,and a depth fusion network. Given optical flow and camera
                    pose, our flow-to-depth layer generates depth proposals and
                    the corresponding confidence maps by explicitly solving an
                    epipolar geometry optimization problem. Our flow-to-depth
                    layer is differentiable, and thus we can refine camera poses
                    by maximizing the aggregated confidence in the camera pose
                    refinement module. Our depth fusion network can utilize depth
                    proposals and their confidence maps inferred from different adjacent frames to produce the final depth map. Furthermore, the
                    depth fusion network can additionally take the depth proposals
                    generated by other methods to improve the results further. The
                    experiments on three public datasets show that our approach
                    outperforms state-of-the-art depth estimation methods, and has
                    reasonable cross dataset generalization capability: our model
                    trained on KITTI still performs well on the unseen Waymo
                    dataset. Our source codes are publicly available at https://github.com/jiaxinxie97/Video-depth-estimation.git.
                </p>
            </div>
        </div>

        
        <!-- ##### Overview video #####-->
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
              <h3>
                  Technical Video
              </h3>
              <div class="text-center">
                  <div style="position:relative;padding-top:56.25%;">
                      <!-- <iframe src="https://youtu.be/07A3aRF4s0g" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe> -->
                    <iframe width="560" height="315" src="https://www.youtube.com/watch?v=ajwKvvoxeHw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                  </div>
              </div>
          </div>
        </div>

        <!-- ##### Motivation & Key idea #####-->
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
              <h3>
                Motivation & Key idea
              </h3>
              <p class="text-justify">
We have presented a video depth estimation method that
builds upon a novel flow-to-depth layer. This layer can help
refine camera poses and generate depth proposals. Beyond the
depth proposals computed from the flow-to-depth layer, depth
maps estimated by other methods can also serve as depth
proposals in our model. In the end, a depth fusion network
fuses all depth proposals to generate a final depth map. 
              </p>
<!--               <img src="pip_bg.png" class="img-responsive" alt="bac">
 -->              


          </div>
        </div>

        <!-- ##### Architecture #####-->
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
              <h3>
                  Architecture
              </h3>
              <img src="../images/framework.png" class="img-responsive" alt="DVP Overview" class="center"><br>
              <p class="text-justify">
First, we estimate the optical flow from the video frames and obtain initial camera poses from GPS and
IMU or applying odometry algorithms. Second, the initial camera poses are refined by maximizing the sum of confidence map in pose refinement module.
Third, generating depth proposals and confidence maps with refined camera poses through the flow-to-depth layer. Finally, we obtain the final depth map by
a depth fusion network that fuses the given depth proposals, confidence maps and target frame.

              </p>
          </div>
        </div>
        
        <!-- ##### BibTex #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{xie2019video,
  title={Video Depth Estimation by Fusing Flow-to-Depth Proposals},
  author={Xie, Jiaxin and Lei, Chenyang and Li, Zhuwen and Li, Li Erran and Chen, Qifeng},
  journal={arXiv preprint arXiv:1912.12874},
  year={2019}
}
}
                    </textarea>
                </div>
            </div>
        </div>

    </div>
</body>
</html>
