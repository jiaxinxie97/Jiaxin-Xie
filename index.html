<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Jiaxin Xie (谢佳芯)</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jiaxin Xie (谢佳芯)</name>
              </p>
              <p>Jiaxin Xie is a fifth year Ph.D. student at the Hong Kong University of Science and Technology (HKUST), supervised by <a href="https://cqf.io">Qifeng Chen</a>. She obtained her Bachelor's degree at Wuhan University in 2018.  
              </p>
<!--               <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:jiaxinxie1997@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://github.com/jiaxinxie97/"> Github</a> &nbsp/&nbsp 
                <a href="https://scholar.google.com/citations?user=MPelrrUAAAAJ&hl=en/">Google Scholar</a>
             
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/github_icon.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_crop.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    
<!--           <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vase_small.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>arXiv</em>, 2020  
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">video</a>
        /
              <a href="https://github.com/bmild/nerf">code</a>
              <p></p>
              <p>
              Training a tiny non-convolutional neural network to reproduce a scene using volume rendering achieves photorealistic view synthesis.</p>
            </td>
          </tr>  -->
          
         <tr onmouseout="RNCR_stop()" onmouseover="RNCR_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='RNCR_image'>
                  <img src='images/HFGI3D.png' width="160"></div>
                <img src='images/HFGI3D1.png' width="160">
              </div>
              <script type="text/javascript">
                function RNCR_start() {
                  document.getElementById('RNCR_image').style.opacity = "1";
                }

                function RNCR_stop() {
                  document.getElementById('RNCR_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>High-fidelity 3D GAN Inversion by Pseudo-multi-view Optimization</papertitle>
              </a>
              <br>
                  </strong> Jiaxin Xie * </strong>, 
                  <a href="https://ken-ouyang.github.io/">Hao OUYANG*</a>, 
                  Jingtan Piao, 
                  <a herf='https://chenyanglei.github.io/'>Chenyang Lei</a>,
                  <a href="https://cqf.io/">Qifeng Chen</a>
              <br>
                 Arxiv   
              <br>
              <a href="https://arxiv.org/abs/2211.15662">arxiv</a> / 
              <a href="https://ken-ouyang.github.io/HFGI3D/index.html">project website</a> / 
              <a href="https://github.com/jiaxinxie97/HFGI3D">code</a>
              <p></p>
              <p> </p>
            </td>
          </tr>
          <tr onmouseout="sr_iccv21_stop()" onmouseover="sr_iccv21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sr_iccv21_image'>
                  <img src='images/sr_iccv21_after.jpeg' width="160"></div>
                <img src='images/sr_iccv21_before.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function sr_iccv21_start() {
                  document.getElementById('sr_iccv21_image').style.opacity = "1";
                }

                function sr_iccv21_stop() {
                  document.getElementById('sr_iccv21_image').style.opacity = "0";
                }
                sr_iccv21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Dual-Camera Super-Resolution with Aligned Attention Modules  </papertitle>
              </a>
              <br>
               <a herf='https://tengfei-wang.github.io/'>Tengfei Wang*</a>,
               </strong> Jiaxin Xie * </strong>,
                <a herf='http://wenxiusun.com/'>Wenxiu Sun</a>,
                 <a herf='https://scholar.google.com/citations?user=uT9CtPYAAAAJ&hl=en'>Qiong Yan</a>,
                 <a href="https://cqf.io/">Qifeng Chen</a>
              <br>
              <em>ICCV </em>, 2021  <strong style="color:red"> (Oral Presentation)</strong>
              <br>
              <a href="https://arxiv.org/abs/2109.01349">arxiv</a> / 
              <a href="https://github.com/Tengfei-Wang/DCSR">code</a> /  
              <a href="https://tengfei-wang.github.io/Dual-Camera-SR/index.html">project website</a> /
              <a href="https://github.com/Tengfei-Wang/DCSR">dataset</a> /  
              <a href="https://youtu.be/5TiUfAcNvuw">video</a> 
              <p></p>
              <p style="color:red"> First real-world dual-camera super-resolution approach. <br>
               A new high-quality dataset for dual-camera zoom (telephoto and wide-angle). </p>
            </td>
          </tr>
          <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sfp_image'>
                  <img src='images/sfp_after.png' width="160"></div>
                <img src='images/sfp_before.png' width="160">
              </div>
              <script type="text/javascript">
                function sfp_start() {
                  document.getElementById('sfp_image').style.opacity = "1";
                }

                function sfp_stop() {
                  document.getElementById('sfp_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Shape from Polarization for Complex Scenes in the Wild</papertitle>
              </a>
              <br>
               <a herf='https://chenyanglei.github.io/'>Chenyang Lei*</a>,
               <a herf='https://github.com/ChenyangQiQi'>Chenyang Qi*</a>,
              <strong>Jiaxin Xie*</strong>,
              Na Fan, 
              <a href="http://vladlen.info/">Vladlen Koltun </a>, 
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>CVPR</em>, 2022  
              <br>
              <a href="https://arxiv.org/pdf/2112.11377.pdf">arxiv</a> / 
              <a href="https://github.com/ChenyangLEI/sfp-wild">code</a>  

              <p></p>
              <p>We present a new data-driven approach with physics-based priors to scene-level normal estimation from a single polarization image. </p>
            </td>

          </tr>
          
          <tr onmouseout="videodepth_stop()" onmouseover="videodepth_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='videodepth_image'>
                  <img src='images/depth_after.JPG' width="160"></div>
                <img src='images/depth_before.JPG' width="160">
              </div>
              <script type="text/javascript">
                function videodepth_start() {
                  document.getElementById('videodepth_image').style.opacity = "1";
                }

                function videodepth_stop() {
                  document.getElementById('videodepth_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1912.12874.pdf">
                <papertitle>Video Depth Estimation by Fusing Flow-to-Depth Proposals</papertitle>
              </a>
              <br>
              <strong>Jiaxin Xie</strong>,
              <a herf='https://chenyanglei.github.io/'>Chenyang Lei</a>,
              <a href="https://scholar.google.com/citations?user=gIBLutQAAAAJ&hl=en">Zhuwen Li</a>,
              <a href="http://www.cs.columbia.edu/~lierranli/">Li Erran Li</a>,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>IROS </em>, 2020  
              <br>
              <a href="https://arxiv.org/pdf/1912.12874.pdf">arXiv</a> /
              <a href="https://jiaxinxie97.github.io/Jiaxin-Xie/FDNet/FDNet">project page</a> /
              <a href="https://github.com/jiaxinxie97/Video-depth-estimation">code</a>
              <p></p>
              <p>We present an approach with a differentiable flow-to-depth layer for video depth estimation.</p>
            </td>
          </tr>  

          <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='DepthSensing'><img src='images/depth_sensing.png'></div>
                <img src='images/depth_sensing.png'>
              </div>
              <script type="text/javascript">
                function motionblur_start() {
                  document.getElementById('DepthSensing').style.opacity = "1";
                }

                function motionblur_stop() {
                  document.getElementById('DepthSensing').style.opacity = "0";
                }
                motionblur_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Depth Sensing Beyond LiDAR Range</papertitle>
              </a>
              <br>
              <a href="https://kai-46.github.io/website/">Kai Zhang</a>,
              <strong>Jiaxin Xie</strong>,
              <a href="http://www.cs.cornell.edu/~snavely/">Noah Snavely</a>,
              <a href="https://cqf.io/">Qifeng Chen</a>
              <br>
              <em>CVPR</em>, 2020 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2004.03048">arxiv</a> /
              <a href="https://kai-46.github.io/DepthSensing/">project page</a> /
              <a href="https://github.com/Kai-46/DepthSensingBeyondLiDARRange">code</a> 
              <p></p>
              <p>We propose a novel cost-effective camera-based solution to sense the depth of distant objects that are not reachable by typical LiDARs. This can be particularly helpful for heavily-weighted autonomous trucks.</p>
            </td>
          </tr>
    <!-- 
          <tr onmouseout="lighthouse_stop()" onmouseover="lighthouse_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lh_image'><video width=100% height=100% muted autoplay loop>
                <source src="images/rings_crop.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/rings.png' width="160">
              </div>
              <script type="text/javascript">
                function lighthouse_start() {
                  document.getElementById('lh_image').style.opacity = "1";
                }

                function lighthouse_stop() {
                  document.getElementById('lh_image').style.opacity = "0";
                }
                lighthouse_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://people.eecs.berkeley.edu/~pratul/lighthouse/">
                <papertitle>Lighthouse: Predicting Lighting Volumes for Spatially-Coherent Illumination</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://research.google/people/RichardTucker/">Richard Tucker</a>,
              <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>
              <br>
        <em>CVPR</em>, 2020  
              <br>
              <a href="https://people.eecs.berkeley.edu/~pratul/lighthouse/">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08367">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=KsiZpUFPqIU">video</a>
              <p></p>
              <p>We predict a volume from an input stereo pair that can be used to calculate incident lighting at any 3D point within a scene.</p>
            </td>
          </tr>  




          <tr onmouseout="friendly_stop()" onmouseover="friendly_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='friendly_image'><img src='images/friendly_after.png'></div>
                <img src='images/friendly_before.png'>
              </div>
              <script type="text/javascript">
                function friendly_start() {
                  document.getElementById('friendly_image').style.opacity = "1";
                }

                function friendly_stop() {
                  document.getElementById('friendly_image').style.opacity = "0";
                }
                friendly_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1w_0djhL0QgC_fbehnJ0c-J23_kW_420p/view?usp=sharing">
                <papertitle>A Hardware-Friendly Bilateral Solver for Real-Time Virtual Reality Video</papertitle>
              </a>
              <br>
              <a href="https://homes.cs.washington.edu/~amrita/">Amrita Mazumdar</a>, <a href="http://homes.cs.washington.edu/~armin/">Armin Alaghi</a>, <strong>Jonathan T. Barron</strong>, <a href="https://www.cs.unc.edu/~gallup/">David Gallup</a>, <a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze</a>, <a href="https://homes.cs.washington.edu/~oskin/">Mark Oskin</a>, <a href="http://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>
              <br>
              <em>High-Performance Graphics (HPG)</em>, 2017
              <br>
              <a href="https://sampa.cs.washington.edu/projects/vr-hw.html">project page</a>
              <p></p>
              <p>A reformulation of the bilateral solver can be implemented efficiently on GPUs and FPGAs.</p>
            </td>
          </tr> -->

        </tbody></table>

        
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching Assistant</heading>
                <ul>
                  <li>COMP 1029J: Java Programming Bridging Course (Fall 2020)</li>
                  <li>COMP 1029C: C Programming Bridging Course (Fall 2020)</li>
                  <li>COMP 4331 : Introduction to Data Mining (Fall 2019)</li>              
                </ul>

<!--               <p>
              COMP 4901J: Deep Learning in Computer Vision (Spring 2019)
              </p>
              <p>
               COMP 3031: Principle of Programming Languages (Fall 2019)
              </p>
 -->            </td>
          </tr>
        </tbody></table>

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Honors and Awards</heading>
                <ul>
                  <li>HKPFS, 2018</li>
                  <li>National Scholarship, 2016,2017</li>        
                </ul>

<!--               <p>
              National Scholarship, 2017
              </p>
              <p>
              Outstanding Graduate (Zhejiang University), 2018
              </p>
              <p>
              Texas Instruments Scholarship, 2017
              </p>
              <p>
              First-Class Scholarship for Outstanding Merits, 2017
              </p>
              <p>
              Excellent Student Award, 2016, 2017
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">Thank <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing the source code of his personal page.</p>
                <!-- <br> -->
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
